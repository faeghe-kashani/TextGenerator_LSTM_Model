{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Character-level text generation with LSTM\n",
        "\n",
        "## Introduction\n",
        "This example demonstrates how to use a LSTM model to generate text character-by-character.\n",
        "\n",
        "At least 20 epochs are required before the generated text starts sounding locally coherent.\n",
        "\n",
        "It is recommended to run this script on GPU, as recurrent networks are quite computationally intensive.\n",
        "\n",
        "If you try this script on new data, make sure your corpus has at least ~100k characters. ~1M is better.\n",
        "https://keras.io/examples/generative/lstm_character_level_text_generation/\n",
        "\n",
        "\n",
        "- more examples:\n",
        "  * Keras model: https://www.kaggle.com/code/shivamb/beginners-guide-to-text-generation-using-lstms\n",
        "  * Pytorch model: https://www.kdnuggets.com/2020/07/pytorch-lstm-text-generation-tutorial.html\n",
        "\n",
        "\n",
        "\n",
        "- more text corpus:\n",
        "  *  [Project Gutenberg](https://www.gutenberg.org/ebooks/search/%3Fsort_order%3Ddownloads)\n",
        "  * [Alice’s Adventures in Wonderland by Lewis Carroll.](https://www.gutenberg.org/ebooks/11)\n",
        "  * [ASCII format (Plain Text UTF-8)](https://www.gutenberg.org/cache/epub/11/pg11.txt)"
      ],
      "metadata": {
        "id": "tI1UrmlZRmu0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lIYdn1woOS1n"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import sys\n",
        "import numpy as np\n",
        "from keras import layers\n",
        "from tensorflow import keras\n",
        "import pickle\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Prepare the data\n",
        "path = keras.utils.get_file(\n",
        "    'nietzsche.txt',\n",
        "    origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt',\n",
        "    )\n",
        "\n",
        "text = open(path).read().lower()"
      ],
      "metadata": {
        "id": "u_T6oI9bSB5d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ceaf972b-dae0-4fc7-d0c2-7511aa0d4de7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/nietzsche.txt\n",
            "600901/600901 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text[0: 100]"
      ],
      "metadata": {
        "id": "k-22ecptYyPQ",
        "outputId": "dc47b22c-ffaf-4f46-db1d-ce47fe33061c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'preface\\n\\n\\nsupposing that truth is a woman--what then? is there not ground\\nfor suspecting that all ph'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create mapping of unique chars to integers\n",
        "chars = sorted(list(set(text)))\n",
        "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
        "print(char_to_int)"
      ],
      "metadata": {
        "id": "VpevkzEWlTZB",
        "outputId": "be383008-851b-43e4-cf29-936b986db327",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'\\n': 0, ' ': 1, '!': 2, '\"': 3, \"'\": 4, '(': 5, ')': 6, ',': 7, '-': 8, '.': 9, '0': 10, '1': 11, '2': 12, '3': 13, '4': 14, '5': 15, '6': 16, '7': 17, '8': 18, '9': 19, ':': 20, ';': 21, '=': 22, '?': 23, '[': 24, ']': 25, '_': 26, 'a': 27, 'b': 28, 'c': 29, 'd': 30, 'e': 31, 'f': 32, 'g': 33, 'h': 34, 'i': 35, 'j': 36, 'k': 37, 'l': 38, 'm': 39, 'n': 40, 'o': 41, 'p': 42, 'q': 43, 'r': 44, 's': 45, 't': 46, 'u': 47, 'v': 48, 'w': 49, 'x': 50, 'y': 51, 'z': 52, 'ä': 53, 'æ': 54, 'é': 55, 'ë': 56}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_chars = len(text)\n",
        "n_vocab = len(chars)\n",
        "print(\"Total Characters: \", n_chars)\n",
        "#list of unique chars in the corpus\n",
        "print('Total Unique Characters: ', len(chars))\n",
        "#dictionary mapping unique chars to their index in 'chars'\n",
        "char_indices = dict((char, chars.index(char)) for char in chars)"
      ],
      "metadata": {
        "id": "iWDR0rEilc0J",
        "outputId": "a30a50ba-c1ad-43fb-8913-39da62c876c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Characters:  600893\n",
            "Total Unique Characters:  57\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#length of extracted char sequence\n",
        "max_len = 40\n",
        "\n",
        "#we sample a new sequence every 'step' char\n",
        "step = 3 #sliding window\n",
        "\n",
        "#sentences holds our extracted sequence\n",
        "sentences = []\n",
        "\n",
        "#holding the targets or labels (the following chars)\n",
        "next_char = []\n",
        "\n",
        "#mini-batch\n",
        "for i in range(0, len(text)-max_len, step):\n",
        "  sentences.append(text[i: i+max_len])\n",
        "  next_char.append(text[i+max_len]) #label\n",
        "print('Total Sentence: ', len(sentences))\n",
        "\n",
        "#the chars one-hot representation into binary arrays\n",
        "x = np.zeros((len(sentences), max_len, len(chars)), dtype=np.bool)\n",
        "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
        "for i, sentence in enumerate(sentences):\n",
        "  for t, char in enumerate(sentence):\n",
        "    x[i, t, char_indices[char]] = 1\n",
        "  y[i, char_indices[next_char[i]]] = 1"
      ],
      "metadata": {
        "id": "ZSoSrIUKY00Z",
        "outputId": "6f1cdcf5-94e6-425f-c2c2-a7456314ab35",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Sentence:  200285\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the model: a single LSTM layer\n",
        "model = keras.models.Sequential()\n",
        "model.add(layers.LSTM(128, input_shape=(max_len, len(chars))))\n",
        "model.add(layers.Dense(len(chars), activation='softmax'))"
      ],
      "metadata": {
        "id": "VN6QhOvEY7Vf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#compile the model\n",
        "opt = keras.optimizers.RMSprop(lr=0.01)\n",
        "lss = keras.losses.CategoricalCrossentropy()\n",
        "model.compile(loss=lss, optimizer=opt)"
      ],
      "metadata": {
        "id": "e-UdSLAsY9Lv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prepare the text sampling function\n",
        "\n",
        "In order to control the amount of stochasticity in the sampling process, we’ll introduce a parameter called the softmax temperature that characterizes the entropy of the probability distribution used for sampling: it characterizes how surprising or predictable the choice of the next character will be."
      ],
      "metadata": {
        "id": "xKIVP96WR-DU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#pick a weighted random char based on probability of next_char instead of maximum probability\n",
        "def sample(preds, temprature=1.0):\n",
        "  preds = np.asarray(preds).astype('float64')\n",
        "  preds = np.log(preds) / temprature\n",
        "  exp_preds = np.exp(preds)\n",
        "  preds = exp_preds / np.sum(exp_preds)\n",
        "  probas = np.random.multinomial(1, preds, 1)\n",
        "  return np.argmax(probas)\n",
        "\n",
        "#look at the below digram from François Chollet book (chapter 8)!"
      ],
      "metadata": {
        "id": "cWfQKNUTY_Go"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "hQD7sgWcZD8q",
        "outputId": "86042a17-acf5-45e8-8171-2ed5cbd2bcab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#train the model\n",
        "checkpoint_filepath = '/content/gdrive/MyDrive/CheckPoints/LSTMGeneratingtext/'\n",
        "model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=True,\n",
        "    # monitor='loss',\n",
        "    # mode='auto',\n",
        "    # save_best_only=True\n",
        "    )\n",
        "try:\n",
        "  with open(checkpoint_filepath + '/Params.pickle', 'rb') as handle:\n",
        "    start_epoch = pickle.load(handle)\n",
        "    model.load_weights(checkpoint_filepath)\n",
        "    print('starting from epoch = ', start_epoch)\n",
        "except:\n",
        "  print('Checkpoint not loaded')\n",
        "  start_epoch = 1\n",
        "\n",
        "for epoch in range(start_epoch, 100):\n",
        "  print('epoch', epoch)\n",
        "  # fit the model\n",
        "  model.fit(x, y, batch_size=128, epochs=1, callbacks=[model_checkpoint_callback])\n",
        "\n",
        "  #updaing (dumpping) pickle\n",
        "  with open(checkpoint_filepath + '/Params.pickle', 'wb') as handle:\n",
        "    pickle.dump(epoch, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "  #select a text seed at random\n",
        "  start_index = random.randint(0, len(text)-max_len-1)\n",
        "  generated_text = text[start_index: start_index+max_len]\n",
        "  print('----------------generating with seed: \"', generated_text, '\"')\n",
        "\n",
        "  if epoch % 99 != 0:\n",
        "    continue\n",
        "\n",
        "  for temperature in [0.2, 0.5, 1.0, 1.2]:\n",
        "    print('----------------------temperature----------------------: ', temperature)\n",
        "    print(generated_text)\n",
        "    #generating 400 chars for instance\n",
        "    for i in range(50):\n",
        "      sampled = np.zeros((1, max_len, len(chars)))\n",
        "      for t, char in enumerate(generated_text):\n",
        "        sampled[0, t, char_indices[char]] = 1\n",
        "\n",
        "        preds = model.predict(sampled, verbose=0)[0]\n",
        "        next_index = sample(preds, temperature)\n",
        "        next_character = chars[next_index]\n",
        "\n",
        "        generated_text = generated_text[1: ]\n",
        "        generated_text += next_character\n",
        "\n",
        "        # sys.stdout.write(next_char)\n",
        "        # sys.stdout.flush()\n",
        "\n",
        "      print(generated_text)"
      ],
      "metadata": {
        "id": "ftYk_G7TZJZ5",
        "outputId": "69a0485e-ca5f-4423-ddf6-ad20995ef8e3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "starting from epoch =  76\n",
            "epoch 76\n",
            "1565/1565 [==============================] - 16s 6ms/step - loss: 1.2310\n",
            "----------------generating with seed: \" e, perhaps, that our new language sounds \"\n",
            "epoch 77\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 1.2323\n",
            "----------------generating with seed: \" difficult for\n",
            "a noble man to understand: \"\n",
            "epoch 78\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 1.2310\n",
            "----------------generating with seed: \" he semi-animal poverty of their souls. r \"\n",
            "epoch 79\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 1.2299\n",
            "----------------generating with seed: \" ispleasure, if not scorn and pity philos \"\n",
            "epoch 80\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 1.2309\n",
            "----------------generating with seed: \" hat there is\n",
            "something lacking in them:  \"\n",
            "epoch 81\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 1.2272\n",
            "----------------generating with seed: \" e taken of children who cry and scream i \"\n",
            "epoch 82\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 1.4008\n",
            "----------------generating with seed: \"  believe that anybody ever looked into t \"\n",
            "epoch 83\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 1.2483\n",
            "----------------generating with seed: \" in of good and evil.=--the notion of goo \"\n",
            "epoch 84\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 1.2351\n",
            "----------------generating with seed: \" nature, nor his motives, nor his [course \"\n",
            "epoch 85\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 1.2313\n",
            "----------------generating with seed: \" doubt that it will be over still sooner  \"\n",
            "epoch 86\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 1.2324\n",
            "----------------generating with seed: \" g below us, a\n",
            "vastly extensive order, (o \"\n",
            "epoch 87\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 1.2328\n",
            "----------------generating with seed: \" ithout danger. as far as i understand th \"\n",
            "epoch 88\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 1.2276\n",
            "----------------generating with seed: \"  of the\n",
            "balance of cheerfulness and desp \"\n",
            "epoch 89\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 1.2264\n",
            "----------------generating with seed: \" ar without forgetfulness! a poet could s \"\n",
            "epoch 90\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 1.2300\n",
            "----------------generating with seed: \" r feelings and doings are, at bottom, ac \"\n",
            "epoch 91\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 1.2271\n",
            "----------------generating with seed: \" faculty; belief in unconditioned substan \"\n",
            "epoch 92\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 1.2306\n",
            "----------------generating with seed: \" in, as\n",
            "is usual in the case of tooth ach \"\n",
            "epoch 93\n",
            "1565/1565 [==============================] - 11s 7ms/step - loss: 1.2286\n",
            "----------------generating with seed: \"  is always paradise\":\n",
            "so say the most an \"\n",
            "epoch 94\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 1.2283\n",
            "----------------generating with seed: \" t that\n",
            "man is the animal not yet properl \"\n",
            "epoch 95\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 1.2342\n",
            "----------------generating with seed: \"  plant has always grown.\n",
            "indeed, to unde \"\n",
            "epoch 96\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 9.7137\n",
            "----------------generating with seed: \" aining of the limbs, acts of madness) si \"\n",
            "epoch 97\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 13.8737\n",
            "----------------generating with seed: \" hereto, which, as we have said, france h \"\n",
            "epoch 98\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 11.8841\n",
            "----------------generating with seed: \" ured, even the learned, and perhaps phil \"\n",
            "epoch 99\n",
            "1565/1565 [==============================] - 10s 6ms/step - loss: 12.2783\n",
            "----------------generating with seed: \" hich they\n",
            "rest became extinct? but the r \"\n",
            "----------------------temperature----------------------:  0.2\n",
            "hich they\n",
            "rest became extinct? but the r\n",
            "ttt  t   e  nt  n   ttt  n          n a(\n",
            "    o n   t s            n tt       e   \n",
            "              e  n         ets   n  teth\n",
            " nt      t   t    s       e      i  t  e\n",
            " sott ss     e   e    t    t      ee   r\n",
            "         s t      e   o t      t   e n p\n",
            "e  t t      n    e n t  t  r  e e      e\n",
            " e   se  s e   e st      n         i    \n",
            "  t  ot nt   t    n  i  sno  e         h\n",
            " et    e  t    tt e      t   t   i    te\n",
            "e         t t  tt    e e   tt    s  t  d\n",
            " tt  a  ot   tt o           t  s ee  sdx\n",
            "      e treotts  to t nt n  et      s  p\n",
            "      o    nt   e       n       s      o\n",
            "e nr        en     t   en      t tr  t n\n",
            "    n     t nt        t  t         ottte\n",
            "et  t   nn ton   t    t   i       e   s \n",
            "e o     t e              n   oe  e    et\n",
            "   t   n      s  n   t   te sr e t   e n\n",
            "  n        o     en t    s n n   ne    o\n",
            "      e  ti  tn  s t           e      to\n",
            "    t tn tt  n    t n n     oe t l s t t\n",
            "   n  eti     e n     t  n     s t   tta\n",
            "    n ts   tt n  t     n t tt    rn e  s\n",
            "     t     t e  e    ttn    t      n  t \n",
            " e     tn en       art n       t  l t ei\n",
            " e n     s    t ts t  t   n tnt t      j\n",
            "                ntto      s         eotn\n",
            "  e  s t     st    e                  tt\n",
            "  t t   tn s     ti n ne  t  to  t  t  e\n",
            "  t   n e sose e     e    tn  e      t n\n",
            " n  se   t       r          tti    t  t \n",
            "      a  t    es te                  n e\n",
            "n  tte    s  t ns    n       ett     t l\n",
            "t   t  n    ann    e see   tt    n n   h\n",
            "   etta  t   n    i tt    t   e        a\n",
            " t   tt  t          r tne              s\n",
            "t    e   r    et  n     e   t nt i      \n",
            "     e    t    n e  tt    t ts tta  e  o\n",
            "  e n   t   n    tt  nsn     t       erh\n",
            " n     t             s  e     o a  n  nt\n",
            " nt    tn        t  s   t    n   e tt   \n",
            "  t    n  t n         et nt t tt e  t  d\n",
            " t e   t   e         n      ts   ot   ee\n",
            "t  t     et  te e             t         \n",
            "  t     tt  ent  e  tot  e       t   non\n",
            "  n         oe  n   n s       t      t w\n",
            "  s  i  t o    t    n             n  t k\n",
            "tn  t     e       n t    n   te  e    tq\n",
            "  te en te  e    t   s    t  ne   t    o\n",
            "----------------------temperature----------------------:  0.5\n",
            "  te en te  e    t   s    t  ne   t    o\n",
            "u  o ernned r nrd or  trne n isctio  nt \n",
            " nn toen  onnsen  rnnstiertntltes s tatc\n",
            " sene nlsnent  l  t efoo ta te l o e en \n",
            "te a st otst\n",
            " raenn eo to aenntnnni c ew\n",
            "eti ntnstse o t    neio r t tt rp\n",
            "n irs \n",
            "t ioeennsr e cte trtots aie m tnsi tat v\n",
            "or  tn  en  nnar sronnnndt t t t to iseu\n",
            "  e  o tn ntoitutosr eeoeateloss  en  s \n",
            "iinon  nstm  n on ddtco  l ncdnot ooo nn\n",
            " n intet int  rea er nto  tr etandosro w\n",
            "ot  a tns  rata s  ios  innne lntet n no\n",
            " tnenrtnono t e o  etnt rteo e i n iimo?\n",
            " ttn  eeenn  n es id n g  eee  e si se  \n",
            "reeeodesn a t   c   eisnsonrnorctin    t\n",
            "s ot c ttli tn au   dt e el tnntnrrs tno\n",
            " t ottsdti tntu o  s sfooea rn  ot ot  e\n",
            "n esta  nt s   taou incosranu t  sos toa\n",
            " e ino roe c esii ia  sisne  tr nie ep t\n",
            "dd ssesat eo nerteiueniia feoesirt  neth\n",
            " s i    t   rtn o  ofm ie rditsoi ro in \n",
            "  estt    tsr ie td tt   tniee rele    t\n",
            "e oe strdsotnee  n    t n  enrets  ttto \n",
            "  nr fo tos t ssl  nentnei  n  s  rts l=\n",
            "iie  nn i rt otei   s tinitseiuenneie or\n",
            " nt ites   tr  ttati oesl   tlio  eisose\n",
            "oncairtes ae sttotsn   n erreslnnt  iaos\n",
            "tnln nsoa lenno e t o eenn  o n   esltiw\n",
            "trieontt eo riee o neann t i tt  ne nnt \n",
            " te d tt e et onti ot rt a intnaa in  si\n",
            "t eeotnsetta oeous r ne e tnitdelte or  \n",
            "ri  c itotcntoi  oit ert t  ieteneii   t\n",
            "netttiotm re  s  nr  ttn etslat al t rei\n",
            "tel   cn ile irl ds  tnu o e nt    rrrth\n",
            "ro nsrenafsn  l estaotuoi  na l ii sod e\n",
            " eeceei ue t\n",
            "lec i tt  \n",
            "an n lr  nrct ei\n",
            " oit te  ae t     et s nr t dsiuni trsne\n",
            "tmrot ott  ltsonr  settr oi o e nltstsei\n",
            "   lnlt  tnl n eastr s  etseetorriitns n\n",
            "netd nt tt a   entenon  snn nruosn o t ?\n",
            "e  c o ts   ees nlu i  t ut us  t n\n",
            " nos\n",
            "nionetotr st s  tt  csl l tttt etoda nn \n",
            " ao etn ntls  s s ot  nidlnt n po  nre a\n",
            "ito nnre tetd nnen ear  s   ttnstoete pe\n",
            "oe sints t  ss   s ostesftniss e n odt r\n",
            " c o no  n t loi   t o estinto sattrr  n\n",
            "ree ie e ntl sa t    itletnasrtettott so\n",
            " sl\n",
            " tsotoontntras i  ttt een t i t i tn\n",
            "ue   rteene tnse en  n  eeaimi  en   tac\n",
            "s   i   t e e sis\n",
            "s   neeinntlaui tn rjx\n",
            "sinnns nt   t t ter tl or  astoto o tiov\n",
            "----------------------temperature----------------------:  1.0\n",
            "sinnns nt   t t ter tl or  astoto o tiov\n",
            "  p orc  nr\n",
            "ncnnieaid\n",
            "sseennt iulle oo u\n",
            "  ni lin df si ilieita\n",
            "s ritsuet fencmn.\n",
            "eu fsontlelofnie rae eeau o  praec ntfr\n",
            "\n",
            "nsnettnoreren tlnoatolotsifrm\n",
            "nu otn ato\n",
            " nnsnt neoli mdrcea dntsiinitcptnon tii \n",
            "oninrs\n",
            "ate nsest o i reid tnlrntnaaa  pw\n",
            "rts an el nis int muc\n",
            "stl faadn\n",
            "rtslnoii\n",
            "o naotsdtrer  ue ndfitfaei a rantartitfc\n",
            "c tia es  rsertuftelddualfottn mrn \n",
            " a e\n",
            " tdd srnm ts nandr etgadc\n",
            "ioe f iop msoo\n",
            "torlot srtstetsssgenesestt sa aarsscon  \n",
            "a   los dtloae tie lefsutp atts iti\n",
            " oui\n",
            "eo    aoa neentnrleatectt do aitaofolper\n",
            "sndtaletdrrnsd nors ona no eat el dnsuo \n",
            "titnnsup c teapposioniamei  tsoittcu cef\n",
            "aeensoid   nstsiaon ceolnonreulsatsleud \n",
            "im unticiidtseonsedmn trsdlotnnttio alle\n",
            "  ertetlsmtsl usn remdnitsitbeoleergfnui\n",
            "acat ottupctunto io  mocrtoefii\n",
            "i rnr  ?\n",
            "anrt\n",
            "o oe iinesr\n",
            "andtdfs  eoafcn tipnfim\n",
            "entr dostd\n",
            "faprlino l oci fras\n",
            "dtnsuofrr\n",
            "ouu cre e t tormls ler sedldrfsreicpelc-\n",
            "t srifi so  stettind td aioo  eeesltnoau\n",
            "   mtnts tuiime titdodtllrrseo enftetrar\n",
            "\n",
            "estndte  n eanroe cusniea tndotist  lcg\n",
            "ant fmooa oeodergfnotc  ndt reo \n",
            "em a ea\n",
            "loced sll cro afsiun rdcoamue yeomo tedl\n",
            " messtosnu nns dtmgaitcc  esidprns inoeo\n",
            "ttoc onrnen ttnaintctsli ddlulro  snestj\n",
            " cunimticttleo\n",
            "nno \n",
            "eotn crn eftfiilenai\n",
            "tyndlleaao  e sdtemennoaioaseit  usl s  \n",
            "lclissict odnauorntssiecil eca ofrtl   u\n",
            "osoocefotensuriue nioennfic ntlicaene tl\n",
            "e oa rsaf  ltitismdcscssotrodllsce  u  l\n",
            " tseads titlimmniimtiint  sofne  nntierr\n",
            "ui  oonfortpdon ct oaaetu oornprtmsnenie\n",
            " esoldna dnfpieneseia\n",
            "sta itoeocodinnrrr\n",
            " eetsdo t  sdnananrc lcetatd ydler  en r\n",
            "ses  til ss areis ts\n",
            "ioaoaol eosm  cpiea\n",
            "atrc c\n",
            " otirllin t cooot  not  orsfenec2\n",
            "atr sieenteettoo r nt tdatna  etoane ud\"\n",
            "eftasstest sli dm ne tusr nur iaaaefcecn\n",
            "o tyaetoreacirstoiis ntai n  rnitras fsm\n",
            "ceemde ndnr  recrnttcoss er en  rrfoooto\n",
            " lpdneueeaneets e ntd rctrcotismof edo  \n",
            "ncsitgwsn teme idtn eeirnao  ec  aeoiiao\n",
            "i  mle st entoe    adp itea erc \n",
            "neir vb\n",
            "cseto ooieilenoenonnirs dnoiuilet rrn c \n",
            "antlnctet  d nte t ti  s aanr dssnrdoorx\n",
            "stongsoanal sdsttlt    ngsteieurtcceenes\n",
            "----------------------temperature----------------------:  1.2\n",
            "stongsoanal sdsttlt    ngsteieurtcceenes\n",
            "lses,ttcc i nsn adiano  omaeiutai lm eww\n",
            "  eartoarm l arr cnsunr oninnalua fne t \n",
            "efaoladouecaece eiroiannorcsocyer\n",
            "adroih\n",
            "cetse eaonutre ifots o e\n",
            " tc  leodl ierp\n",
            "e diietoesiaittitostlt s ttnni cctt apco\n",
            "cudrd en\n",
            "lrn er adrsrrs r ip\n",
            "rdrdscs\n",
            "ll \n",
            "iiec t  eoecttnac\n",
            "iu i  urflor\n",
            "t tt snlj\n",
            "n ue ugi nel \n",
            "rdl ocitlngepas uecurdcnrn\n",
            "o sn  nnadgs ornnrios onsoiatoeo oior g \n",
            " f ncg mrac\n",
            "oruscdrotaerr\n",
            "n t,eo tdr \n",
            "ta\n",
            "  toeinaia  ldf css odelsf ee olrtstl pn\n",
            "acetunsu nuen\n",
            "etc\n",
            "dias  o\n",
            "rnaas gtd \n",
            "e a\n",
            "ptifairtiin u tisieaoaec aretot\n",
            "t tronem\n",
            "nonocmme \n",
            "sredtiereotnieitant tdptrnscn \n",
            "ei re minntsnsons r erunomreutard rondat\n",
            "i sncstss tnoenatlae\n",
            " lei aetaote slse  \n",
            " rrmre ulnfsrdlind o ii c ofe   fsmenrsa\n",
            "taemc \n",
            "failf \n",
            "neniettroosset\n",
            "ntedue en n\n",
            "itrpe\n",
            "adssslecrc m\n",
            " o nt \n",
            "senugoeuast d\"\n",
            "isliin    nleallupssd eocpulltre tnsurex\n",
            "risletuccnl etepe d  e s\n",
            "\n",
            "rsa mm am, uds\n",
            " sdnror eftrei ra oepssn la snc etm tusy\n",
            "nisctsegmoeonf a stict itrasnnoc l,ntrtä\n",
            "i rnltdsncrusot iedo uriaulumnc t\n",
            "e\n",
            "totc\n",
            "ypptduen tcemlutt cunrenneoosetas\n",
            "lnppt \n",
            "o sntdoosa   lfdinnsr tmcclsra a deorapr\n",
            " tcenstulnoptn cl\n",
            "ucrn orosdal dsttttu a\n",
            "\n",
            "stms p sudd ictlpacut oaats rlrennacdse\n",
            "eocotuncn  roe feu tit it n asdetinrourt\n",
            "uo sln trg ofieetfnimwencft icponiffsl d\n",
            "  oaat  e n norelo ota rea irilcofs  n r\n",
            "sonrrrfn urlnotdnsttsflpu st araotnooets\n",
            "p\n",
            "anelotre siomoep erprt sai lte ssse  h\n",
            "ti o u  dndlera ln non seeginetlti onnob\n",
            "ossandrirs tsc\n",
            "o  ttitennsf i sc onsd oi\n",
            "p oncocut,taaiaos aru ei ritsnorentiianr\n",
            "c ntenmo tt seupeircsl\n",
            "se m m\n",
            "ri n stst \n",
            "sltp ssilnsaccoetsaf l is ttdrrtt noollo\n",
            "cltottsoi  dgooutee t  cla npieoi nloi i\n",
            "u eo lptpdoos tneaidnu   trmrdoto diatte\n",
            " roiopndt\n",
            "orai ito islmscunglotcl ornool\n",
            "i sieospouataslinct\n",
            " el r eeofmoecn retn\n",
            " lidrn eodnfaoollc  in\n",
            "aon otiaenseidtoe\n",
            "mort ays\n",
            "etdru retoeoofunafes ssc\n",
            " restn\n",
            "lnl itttfr ttrd fptademen\n",
            "mon irerdlrou \n",
            " ntpietdsfsuai r ao c tct esilditefeim m\n",
            " nmtucr anoesuodnrndnncnaye  r riln slea\n",
            "ctatn ln tsc rrotn asn petseamosaafm noi\n",
            "elnunrdili e\n",
            "wosnsno ancv si snrle usoos\n",
            "eesorctpsicacocteolstornnumdt \n",
            " edo nttm\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}